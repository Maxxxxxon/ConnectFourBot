
from agents import netAgent, processObservation
from mcts import mcts
from model import SimpleNet
from torch import nn
from kaggle_environments import make
import numpy as np
import torch
from collections import OrderedDict

def processObservation(observation):
    board = np.array(observation['board'])
    if (observation['mark'] == 2):
        ones = np.argwhere(board == 1)
        twos = np.argwhere(board == 2)
        board[ones] = 2
        board[twos] = 1
    return board


def netAgent(network, return_probs=False, incorrect_moves=True):
    if return_probs:
        def agent(observation, configuration=None):
            board = processObservation(observation)
            input = torch.tensor(board, dtype=torch.float32)
            output = network(input)
            probs = torch.softmax(output[0], 0)
            return probs, output[1]
    else:
        def agent(observation, configuration=None, incorrect_moves=incorrect_moves):
            board = processObservation(observation)
            input = torch.tensor(board, dtype=torch.float32)
            output = network(input)
            probs = torch.softmax(output[0], 0)
            if incorrect_moves:
                return torch.argmax(probs).item()
            else:
                action = torch.argmax(probs).item()
                while board[action] != 0:
                    probs[action] = -1
                    action = torch.argmax(probs).item()
                return action
    return agent


ACTIONS_N = 7
U_COEF = 4
MCTS_WAVES = 300
TEMPERATURE = 0.5

CURRENT_N = 1


class Node:
    def __init__(self, value, probs, done=False):
        self.value = value
        self.probs = probs
        self.number = 1
        self.done = done
        self.links = [None] * ACTIONS_N


def mcts(observation, state, agent, against):
    probs, value = agent(observation)
    root = Node(value, probs)
    current_n = 0

    for i in range(MCTS_WAVES):
        current_n += 1
        env = make("connectx", debug=False)
        if (observation['mark'] == 1):
            trainer = env.train([None, against])
        elif (observation['mark'] == 2):
            trainer = env.train([against, None])
        else:
            print("problem with order")
        env.state = state.copy()
        wave(root, agent, trainer, current_n)

    policy = []
    for child in root.links:
        if child is None:
            policy.append(0)
        else:
            policy.append(child.number)
    print(policy)
    policy = np.array(policy)
    policy = policy ** (1 / TEMPERATURE)
    policy = policy / policy.sum()

    return policy


def wave(node, agent, trainer, wave_n):
    if (node.done):
        node.number += 1
        node.value *= (node.number / (node.number - 1))
        return node.value / node.number

    qs = []
    for i, child in enumerate(node.links):
        if child is None:
            qs.append(U_COEF * (0.3 + node.probs[i]) * (wave_n ** 0.5))
        else:
            qs.append(child.value / child.number + U_COEF * (0.3 +
                                                             node.probs[i]) * (wave_n ** 0.5) / (child.number + 1))

    action = int(np.argmax(qs))
    if node.links[action] is None:
        obs, reward, done, info = trainer.step(action)
        # print(obs, reward, done, info)
        probs, value = agent(obs)
        if done:
            value = reward
        if done and reward is None:
            value = torch.tensor(-1.0)
        node.links[action] = Node(value, probs, done)
        return value
    obs, reward, done, info = trainer.step(action)
    value = wave(node.links[action], agent, trainer, wave_n)
    node.value += value
    node.number += 1

    return value


class SimpleNet(torch.nn.Module):
    def __init__(self, input, actions):
        super(SimpleNet, self).__init__()
        self.layer1 = torch.nn.Linear(input, 64)
        self.layer2 = torch.nn.Linear(64, 64)
        self.action_layer = torch.nn.Linear(64, actions)
        self.value_layer = torch.nn.Linear(64, 1)
        self.activation1 = torch.nn.ReLU()
        self.activation2 = torch.nn.ReLU()
        self.tanh = torch.nn.Tanh()

    def forward(self, x):
        x = self.layer1(x)
        x = self.activation1(x)
        x = self.layer2(x)
        x = self.activation2(x)
        action = self.action_layer(x)
        value = self.value_layer(x)
        value = self.tanh(value)
        return action, value


class ComplexNet(torch.nn.Module):
    def __init__(self, input, actions):
        super(SimpleNet, self).__init__()
        self.layer1 = torch.nn.Linear(input, 64)
        self.layer2 = torch.nn.Linear(64, 64)
        self.layer3 = torch.nn.Linear(64, 64)
        self.layer4 = torch.nn.Linear(64, 64)
        self.action_layer = torch.nn.Linear(64, actions)
        self.value_layer = torch.nn.Linear(64, 1)
        self.activation1 = torch.nn.ReLU()
        self.activation2 = torch.nn.ReLU()
        self.activation3 = torch.nn.ReLU()
        self.activation4 = torch.nn.ReLU()
        self.tanh = torch.nn.Tanh()

    def forward(self, x):
        x = self.layer1(x)
        x = self.activation1(x)
        x = self.layer2(x)
        x = self.activation2(x)
        x = self.layer3(x)
        x = self.activation3(x)
        x = self.layer4(x)
        x = self.activation4(x)
        actions = self.action_layer(x)
        value = self.value_layer(x)
        value = self.tanh(value)
        return


model = SimpleNet(42, 7)
model.load_state_dict(OrderedDict([('layer1.weight', tensor([[ 0.1111,  0.0010, -0.1025,  ...,  0.0324, -0.1861, -0.1374],
        [ 0.0337, -0.1302,  0.0104,  ..., -0.0497, -0.0153, -0.0478],
        [-0.0472, -0.0859, -0.0617,  ...,  0.1866,  0.2386, -0.0751],
        ...,
        [-0.0734,  0.0555, -0.1029,  ..., -0.0480, -0.0756, -0.0357],
        [ 0.1092,  0.0235,  0.0899,  ..., -0.1266,  0.2160,  0.0818],
        [-0.0706, -0.0857, -0.0738,  ..., -0.0592, -0.0120, -0.1078]])), ('layer1.bias', tensor([ 0.0541,  0.0577,  0.2105, -0.1336,  0.1062,  0.1119, -0.0408, -0.2141,
         0.1262,  0.1799, -0.1378,  0.0514, -0.1773,  0.1439, -0.0222,  0.0644,
        -0.1485, -0.0818,  0.0197, -0.1466,  0.0721, -0.0146, -0.0870,  0.2057,
        -0.0207, -0.1255,  0.0356, -0.1961, -0.1021,  0.0881, -0.0224, -0.1517,
        -0.0147, -0.0148,  0.2640,  0.1235,  0.0838,  0.0077,  0.2395,  0.0726,
         0.1229, -0.1163, -0.0135, -0.0384, -0.0066, -0.0311, -0.2499, -0.0266,
        -0.0024,  0.0111,  0.0357, -0.1591, -0.1060, -0.0351, -0.0382, -0.1481,
         0.0466, -0.0067,  0.1073,  0.1768,  0.0997,  0.0241, -0.0605, -0.0140,
        -0.1166,  0.1627,  0.0546, -0.1353, -0.1136, -0.0656, -0.1462,  0.1229,
        -0.0532,  0.0193,  0.0489, -0.1227, -0.0438, -0.1295, -0.1868,  0.0887,
        -0.1021,  0.0475, -0.1428,  0.0811, -0.0661, -0.0176, -0.0640, -0.0257,
        -0.0685,  0.0681, -0.0511, -0.1083,  0.1088, -0.0960,  0.0840, -0.0169,
        -0.0042,  0.2612,  0.0160,  0.1452, -0.1202,  0.0514, -0.1130, -0.0631,
        -0.0943, -0.1421,  0.0552,  0.1441, -0.0355,  0.1219, -0.1085,  0.0872,
         0.1205, -0.0115, -0.0323,  0.0291,  0.0321, -0.1371,  0.0316,  0.1525,
         0.1580,  0.1755,  0.0772,  0.0978,  0.0217,  0.1291, -0.0723, -0.0399])), ('res1.layer.weight', tensor([[-0.0427,  0.0290, -0.0509,  ..., -0.0234,  0.0780, -0.0467],
        [-0.0290, -0.0051,  0.0227,  ...,  0.0085, -0.0079, -0.0425],
        [-0.0252,  0.0424, -0.0447,  ...,  0.0427,  0.0023,  0.0091],
        ...,
        [-0.0335,  0.0387, -0.0376,  ..., -0.0457, -0.0805, -0.0267],
        [-0.0711, -0.0397,  0.0421,  ...,  0.0699,  0.0236, -0.0834],
        [ 0.0475, -0.0396,  0.0453,  ...,  0.0359, -0.0003,  0.0399]])), ('res1.layer.bias', tensor([ 3.8775e-02,  9.2205e-02,  1.0408e-03,  8.8485e-02,  4.5673e-02,
         3.2352e-02,  7.1168e-03, -9.2192e-02, -2.2656e-02, -5.9334e-02,
         2.2989e-02,  9.5110e-02, -2.4536e-02,  4.7444e-02,  7.3865e-02,
        -1.8608e-02, -2.4549e-02,  5.8000e-02,  1.0304e-02,  2.8912e-02,
         2.1404e-02, -1.8630e-02,  2.1058e-02,  6.1872e-02,  1.6574e-02,
         5.1392e-02, -7.8403e-02, -3.5930e-02,  1.2296e-02, -4.8822e-02,
        -3.4233e-02, -3.3591e-02, -3.1999e-02, -3.9722e-02,  2.7685e-02,
         1.8917e-02, -2.4756e-02,  1.5528e-02, -4.8434e-02,  7.2318e-03,
        -2.7764e-02,  8.3808e-02,  5.6618e-02, -9.3779e-03,  2.8664e-02,
        -7.5363e-03, -8.1968e-02,  7.4324e-02,  8.4664e-04,  8.3345e-02,
        -1.1253e-02,  6.2324e-03, -7.4254e-03,  6.7349e-02,  2.4230e-02,
        -6.0005e-02, -3.1759e-02, -1.8213e-02,  2.7318e-02, -7.5260e-02,
         8.3583e-03, -7.5537e-02,  7.2489e-02, -5.1995e-02,  6.2924e-02,
        -5.9798e-02,  3.1509e-02, -4.2789e-02,  5.9578e-02, -8.8642e-02,
         7.0164e-02,  2.4184e-02, -2.9944e-02, -8.4834e-03, -2.7041e-02,
         3.8697e-03,  5.2462e-03, -2.9304e-02,  3.1140e-02,  6.9530e-02,
        -2.9330e-02,  2.9090e-02,  4.4597e-02, -5.3104e-02, -7.3335e-02,
         9.7611e-05,  2.7921e-02,  7.7756e-02, -6.5864e-02, -1.6953e-03,
         5.7285e-03, -1.7930e-02, -8.7685e-03,  8.8374e-02, -8.6797e-03,
         3.3383e-02, -2.4458e-02, -2.3311e-02, -1.5919e-02, -1.6300e-02,
         2.1564e-02,  9.0578e-02, -4.3095e-02,  6.3129e-02,  2.8857e-02,
        -3.6894e-02,  2.6976e-02,  5.4161e-02, -3.2841e-02,  6.9817e-02,
         2.2199e-02,  3.3616e-02, -4.8239e-02,  1.9752e-02, -2.9482e-02,
         8.9344e-02, -3.4315e-02, -4.8786e-02, -5.1722e-02, -1.8741e-02,
         4.0384e-02, -4.1943e-02,  1.8947e-02,  7.5181e-02, -6.0569e-02,
         1.1557e-02, -5.9108e-02, -1.1121e-02])), ('res2.layer.weight', tensor([[ 0.0182,  0.0444,  0.0676,  ...,  0.0371, -0.0808, -0.0630],
        [ 0.0818, -0.0745,  0.0264,  ..., -0.0685, -0.0443,  0.0227],
        [-0.0330,  0.0679, -0.0661,  ..., -0.0684, -0.0133, -0.0227],
        ...,
        [ 0.0595, -0.0113, -0.0349,  ...,  0.0696, -0.0427,  0.0756],
        [-0.0579, -0.0599, -0.0149,  ...,  0.0447,  0.0539,  0.0531],
        [-0.0069,  0.0675, -0.0623,  ...,  0.0538,  0.0044,  0.0521]])), ('res2.layer.bias', tensor([-0.0864,  0.0245,  0.0188, -0.0039, -0.0318,  0.0711, -0.0375,  0.0278,
         0.0468,  0.0105, -0.0513, -0.0138, -0.0601,  0.0144,  0.0465,  0.0331,
        -0.0554, -0.0214, -0.0061,  0.0382, -0.0790, -0.0460,  0.0136,  0.0608,
         0.0422, -0.0666,  0.0201,  0.0258,  0.0060,  0.0470, -0.0181,  0.0304,
        -0.0167, -0.0064,  0.0750,  0.0007, -0.0801,  0.0393,  0.0528, -0.0797,
         0.0093, -0.0329, -0.0080, -0.0582, -0.0727, -0.0222, -0.0218,  0.0646,
         0.0221, -0.0661,  0.0312, -0.0794, -0.0800, -0.0066, -0.0721, -0.0040,
         0.0698, -0.0412,  0.0652,  0.0109, -0.0834, -0.0051, -0.0239, -0.0615,
         0.0617, -0.0140,  0.0058,  0.0040,  0.0493,  0.0149,  0.0083,  0.0714,
        -0.0141, -0.0789,  0.0231,  0.0739, -0.0809, -0.0532,  0.0302,  0.0169,
        -0.0565, -0.0302,  0.0696, -0.0202,  0.0248, -0.0636,  0.0354, -0.0687,
        -0.0682, -0.0209, -0.0665, -0.0864, -0.0516,  0.0040, -0.0431, -0.0557,
        -0.0632,  0.0886,  0.0012,  0.0045,  0.0626,  0.0105, -0.0403, -0.0636,
        -0.0928,  0.0765, -0.0546, -0.0491,  0.0548, -0.0044, -0.0503, -0.0499,
        -0.0616,  0.0673, -0.0641, -0.0042, -0.0190,  0.0299,  0.0529,  0.0832,
        -0.0565,  0.0267,  0.0045,  0.0364,  0.0155,  0.0061,  0.0412,  0.0317])), ('res3.layer.weight', tensor([[-0.0780,  0.0236,  0.0788,  ..., -0.0310, -0.0501,  0.0300],
        [-0.0761, -0.0410, -0.0466,  ...,  0.0496,  0.0028, -0.0027],
        [-0.0280,  0.0096, -0.0070,  ..., -0.0353,  0.0290, -0.0647],
        ...,
        [ 0.0248, -0.0840,  0.0156,  ..., -0.0190, -0.0074,  0.0262],
        [ 0.0091,  0.0708,  0.0641,  ..., -0.0797,  0.0571,  0.0517],
        [-0.0269, -0.0274, -0.0151,  ..., -0.0134,  0.0101, -0.0161]])), ('res3.layer.bias', tensor([ 0.0858,  0.0692,  0.0562, -0.0788,  0.0542, -0.0737, -0.0696,  0.0277,
         0.0588, -0.0099, -0.0425,  0.0322,  0.0842,  0.0523, -0.0499, -0.0795,
        -0.0008, -0.0106, -0.0165,  0.0681,  0.0044, -0.0060, -0.0684,  0.0497,
         0.0176, -0.0039, -0.0306,  0.0628,  0.0262,  0.0268, -0.0002, -0.0847,
        -0.0350,  0.0046,  0.0690, -0.0624,  0.0013, -0.0177,  0.0034,  0.0316,
         0.0669,  0.0633, -0.0531, -0.0676, -0.0871, -0.0087,  0.0321,  0.0260,
         0.0265, -0.0037, -0.0795, -0.0791,  0.0090, -0.0229, -0.0074,  0.0444,
        -0.0019,  0.0631, -0.0465, -0.0254, -0.0341,  0.0152, -0.0170,  0.0667,
        -0.0345, -0.0672, -0.0426, -0.0785,  0.0826, -0.0140, -0.0128,  0.0154,
         0.0691,  0.0901,  0.0740, -0.0749,  0.0115,  0.0567,  0.0522, -0.0183,
         0.0358,  0.0537, -0.0583,  0.0176, -0.0842, -0.0495, -0.0197,  0.0506,
        -0.0132, -0.0629,  0.0086,  0.0461, -0.0441, -0.0045,  0.0002,  0.0590,
         0.0548, -0.0344, -0.0352,  0.0475,  0.0534, -0.0043, -0.0316, -0.0509,
         0.0417,  0.0200,  0.0735,  0.0101,  0.0679, -0.0778, -0.0199,  0.0431,
        -0.0840, -0.0059, -0.0417,  0.0435, -0.0049,  0.0454, -0.0715,  0.0457,
         0.0005, -0.0191,  0.0881,  0.0831,  0.0024,  0.0096,  0.0621,  0.0450])), ('action_layer.weight', tensor([[ 1.6703e-02,  1.2838e-02, -7.2741e-02, -3.2987e-02,  1.7741e-02,
         -3.3754e-02, -7.2515e-02, -7.4949e-02, -9.1475e-02,  3.5143e-02,
          1.8341e-02, -2.9278e-02, -8.9683e-02, -6.3703e-02,  6.8708e-02,
         -4.6223e-02, -3.9798e-02,  7.3886e-02, -7.1897e-02, -2.7164e-02,
          5.7020e-02,  7.9493e-02,  7.9025e-02, -1.3774e-02,  5.3447e-02,
          6.7210e-02,  4.1657e-02, -7.8048e-02,  5.3097e-02, -5.1695e-02,
          1.1605e-02, -3.5676e-02,  1.8111e-02,  2.1261e-02, -6.3560e-02,
          1.8675e-02, -3.0087e-02, -2.2163e-02,  5.7494e-02, -2.7639e-02,
         -7.3091e-02, -5.8454e-02,  7.6873e-02, -6.6083e-02, -8.8748e-02,
         -1.4223e-02,  5.3779e-02, -5.1820e-02, -7.3717e-02,  6.5254e-02,
         -7.3887e-02, -3.9436e-02,  1.9690e-02, -5.4167e-02, -1.2652e-01,
          2.9990e-02, -3.7673e-02, -4.7220e-02,  8.4050e-02,  2.7717e-02,
         -4.0217e-02,  1.5822e-03,  2.3547e-04,  1.2652e-02,  5.5372e-02,
          8.0076e-02, -7.8802e-02,  5.9962e-02,  7.6617e-02,  9.9410e-03,
         -3.8913e-02,  2.8172e-02,  6.5534e-02,  1.2609e-02, -7.5133e-02,
          5.4126e-02,  1.9533e-02, -7.0710e-03, -5.2452e-02,  8.5062e-03,
         -7.4589e-04, -4.8819e-02, -1.4374e-02, -4.6459e-02, -3.1421e-02,
         -2.3452e-02,  8.4269e-02, -4.8180e-02, -5.1978e-02, -3.2507e-03,
         -1.1324e-01, -1.5854e-02,  1.3990e-02,  8.4695e-02,  2.8800e-02,
          2.6616e-02, -4.6686e-02, -7.0841e-02,  2.8409e-03,  6.3209e-02,
         -8.5639e-03,  2.3156e-02,  2.9277e-02, -8.1987e-02,  7.4285e-02,
         -2.4126e-02,  5.4473e-03, -6.2359e-02,  5.4743e-02, -6.1515e-02,
         -8.5922e-02,  9.1267e-02, -2.3713e-02, -7.1100e-02, -4.8560e-02,
         -6.1885e-02,  2.6132e-02, -7.2293e-02,  1.0030e-02,  4.6449e-02,
          4.7451e-03,  4.9144e-03, -8.9773e-02,  7.0052e-03, -7.3061e-02,
         -8.5026e-02, -3.0006e-02, -5.3036e-02],
        [ 6.4547e-02,  3.9993e-02, -9.3011e-02,  2.4747e-02,  4.6249e-02,
         -2.1118e-02,  3.4237e-02, -2.2316e-02,  3.8099e-02, -3.5526e-02,
         -3.8743e-02, -1.0638e-01, -2.1684e-02, -2.7668e-03, -3.2070e-02,
          3.8475e-02, -4.8689e-02, -7.0007e-02, -4.4169e-02, -7.6673e-02,
         -6.1718e-02,  1.1034e-02,  4.6827e-02, -9.6940e-02, -5.4986e-02,
          4.4554e-02, -3.5102e-02, -3.8877e-02,  1.0811e-02, -2.1389e-02,
         -5.8589e-02,  4.5441e-02, -3.0872e-02,  8.0409e-02, -5.3468e-02,
         -1.8642e-02, -2.2192e-02,  4.0470e-03,  3.8302e-03, -7.4991e-02,
         -6.4051e-02, -4.0284e-02, -1.3560e-02, -7.9353e-02, -4.1283e-03,
         -5.6899e-02, -7.5342e-03, -2.4221e-02,  2.8344e-02, -9.3258e-02,
         -2.9277e-02,  8.0790e-02, -5.8181e-02,  3.4421e-02,  4.1807e-02,
          1.4386e-02, -4.0105e-02,  1.8618e-02,  6.6234e-02,  7.6622e-02,
          8.4075e-03,  5.6228e-02,  7.6077e-02, -4.9552e-02,  4.9982e-02,
          1.8495e-02,  5.1114e-02,  4.0571e-02,  2.6705e-03, -1.0006e-02,
         -3.6275e-02, -4.7606e-02, -5.5073e-02, -4.4334e-02,  6.1195e-02,
         -6.5759e-02,  6.3686e-02,  7.6364e-02,  1.9803e-02, -4.7284e-02,
         -9.4770e-02,  7.4309e-02, -3.1995e-02, -4.6409e-03, -6.6958e-02,
          4.5421e-02, -4.4903e-03, -8.9142e-02,  3.4416e-02,  2.5166e-02,
          2.0655e-02, -4.3165e-02, -1.1692e-02,  4.6730e-02, -3.1560e-02,
          6.0051e-02, -8.2955e-02, -9.2391e-02,  5.3689e-02, -2.1923e-02,
          5.4569e-02,  1.0249e-02, -5.8656e-02, -6.4776e-02, -2.0039e-02,
         -3.1814e-02, -6.6063e-03,  8.8566e-03, -1.1932e-02,  3.4227e-02,
          6.7589e-02, -3.4696e-02,  2.8177e-02,  7.7694e-02, -1.0612e-01,
         -4.4780e-02,  4.4037e-02, -3.0880e-02,  2.0119e-02,  8.2417e-02,
         -3.0260e-02, -9.6014e-02,  6.9056e-02, -6.2750e-02,  3.8574e-02,
          7.4440e-02, -4.9874e-02,  5.4518e-02],
        [ 2.4259e-02,  1.7070e-02, -3.8791e-02, -1.1213e-02, -2.5711e-02,
         -4.1865e-02,  2.3425e-02,  5.5456e-02,  1.6382e-03, -9.1799e-03,
          7.5617e-02, -1.4698e-02,  2.8030e-02,  5.0465e-03, -1.1873e-02,
         -2.1899e-02,  1.0496e-03,  3.8056e-02,  8.7402e-02, -8.6057e-04,
         -2.2923e-02,  4.2551e-02, -3.5251e-02,  2.4894e-02, -1.7430e-02,
          7.3591e-02,  4.7626e-02,  2.9636e-02,  7.8239e-02,  1.0144e-01,
          3.6111e-02, -2.5707e-02, -6.8566e-02,  3.5685e-02, -6.9521e-02,
         -4.0555e-02, -1.3150e-03,  5.0852e-02, -2.3199e-02, -5.6378e-02,
          2.8371e-02,  6.2508e-02, -3.0446e-03,  9.5591e-02,  1.0173e-03,
          8.0841e-02,  7.0672e-02,  2.8531e-02, -3.8767e-02,  3.9767e-02,
          6.4844e-02, -4.6912e-03,  8.0066e-02, -4.2510e-02,  5.9590e-02,
         -3.5702e-03,  1.0474e-02,  1.0072e-01, -9.5169e-03,  8.1962e-02,
          3.7890e-02,  7.9228e-02, -7.2979e-02,  2.6293e-02,  4.3037e-03,
         -7.7463e-02, -7.8689e-02,  4.4520e-03, -7.4634e-02, -4.1616e-02,
          7.0289e-02,  9.5733e-03,  9.9191e-02,  2.2132e-02, -9.3596e-02,
          5.3055e-02,  2.8699e-02,  3.7744e-02,  1.7302e-02, -4.2125e-02,
         -3.7222e-02,  4.9185e-02,  6.5755e-02, -7.9721e-02,  9.0139e-02,
          4.2315e-03, -4.2304e-03, -3.8424e-02, -1.0833e-02, -3.7343e-02,
          4.5957e-02,  3.2033e-02, -6.5565e-02,  6.3866e-02,  1.7127e-02,
          3.9733e-02, -1.1245e-02,  6.9823e-02, -5.7201e-02,  7.8554e-03,
         -2.5771e-03,  7.3246e-02,  3.9534e-02,  3.2956e-02,  6.0546e-02,
          1.9670e-02, -3.7836e-02,  3.0372e-02, -5.0318e-02, -4.6932e-02,
          1.3067e-02,  4.7500e-02, -7.9987e-02, -3.0042e-02,  2.7147e-02,
          1.6110e-02,  4.7416e-02,  5.0668e-03, -2.4812e-02, -1.0601e-01,
          6.4981e-02, -4.9535e-02,  5.3886e-02, -3.5378e-02, -8.3536e-03,
         -8.8173e-03, -5.0059e-02, -2.5660e-02],
        [-4.3172e-02,  1.1845e-01, -8.5495e-02,  5.7503e-02,  3.6415e-02,
         -5.6257e-03,  1.0112e-01,  4.9044e-02, -2.8582e-02, -3.1928e-02,
          6.4241e-02, -1.6145e-01, -1.5087e-05, -5.4241e-02,  6.0474e-02,
         -5.3470e-02,  2.1793e-02, -3.5928e-02,  8.0562e-02, -4.2677e-02,
         -4.6042e-02,  1.2843e-01,  1.0881e-02, -1.2166e-01, -1.4361e-01,
          5.5459e-02, -3.6191e-02, -2.8788e-02,  2.7187e-02, -1.3869e-02,
         -8.3370e-02,  8.9623e-02,  6.3443e-02,  2.0231e-02, -6.3891e-03,
          5.0067e-02,  3.8369e-02,  5.2608e-02, -5.5233e-02,  8.9151e-02,
         -5.9186e-02,  1.8785e-02, -7.2190e-02, -1.0140e-01,  6.5061e-02,
         -1.8064e-02,  7.7984e-02,  3.6056e-02, -4.6318e-02,  2.8065e-02,
         -3.2857e-02, -3.2369e-02,  6.0186e-02,  1.7546e-03,  3.3973e-02,
          1.5701e-02,  4.7787e-02, -6.7706e-02, -2.7098e-02,  1.1011e-01,
          1.2289e-02, -2.1666e-02,  4.0514e-02,  1.3094e-03,  5.7071e-02,
         -1.0963e-01,  8.3486e-02,  9.5080e-05,  2.2230e-02,  8.9041e-02,
         -4.7331e-02, -1.1047e-01, -6.8393e-05,  4.9036e-02,  2.5396e-01,
         -3.0060e-02, -8.5170e-03, -3.5134e-02,  4.3937e-02, -1.6933e-02,
         -4.1882e-02,  2.1952e-02,  1.4588e-02, -7.4688e-02, -8.4877e-02,
          6.1557e-03,  9.8916e-02, -9.7404e-02,  7.6654e-03,  5.6699e-03,
          7.4352e-02, -1.9958e-02, -2.1688e-02,  1.3351e-01,  7.3544e-02,
         -3.8654e-02, -5.4981e-02, -3.5553e-02, -6.0085e-02, -3.5040e-03,
          4.6209e-02,  6.5862e-03,  2.3234e-02, -2.5020e-02, -4.3870e-03,
          8.7934e-02,  5.1213e-02, -1.1638e-01,  7.2727e-02,  6.9883e-02,
          6.0263e-02, -3.8582e-03, -6.4605e-02, -5.9922e-02, -5.9975e-02,
          4.1792e-02,  1.0324e-01, -7.1419e-02,  5.3618e-03, -4.0273e-02,
          5.0443e-02, -5.8823e-02, -3.1044e-02,  8.3987e-02, -7.2069e-02,
          5.5375e-02,  7.3918e-02,  6.8200e-02],
        [-6.5086e-02,  2.3246e-02, -3.4559e-02,  1.4699e-02,  1.3017e-02,
          1.6605e-03, -6.7714e-02,  2.9862e-02, -6.8679e-02, -6.3739e-02,
         -1.5151e-02, -1.4965e-02,  1.2360e-01, -3.5918e-03,  6.4436e-02,
          1.6208e-02, -2.8352e-02, -3.4455e-02,  6.0935e-02,  1.0717e-01,
          5.5575e-02,  1.3800e-02,  2.1875e-02, -1.4357e-01,  1.3791e-01,
          5.2790e-02,  1.7235e-03, -1.4585e-02, -6.4816e-03, -2.7293e-02,
         -2.2563e-02, -7.2817e-02,  1.9925e-02,  8.7652e-02, -1.0447e-01,
          3.4713e-02,  6.7129e-02, -5.8340e-02, -8.7170e-02, -1.2288e-02,
         -6.8181e-02,  4.7985e-03,  1.1640e-01, -5.3391e-02, -5.9716e-02,
         -5.8077e-02, -3.6494e-02,  2.5001e-02,  6.8699e-02, -1.1562e-01,
          2.0196e-02,  8.8557e-03,  4.9120e-02, -6.4114e-02,  2.0206e-01,
         -6.9081e-02, -7.2201e-02,  8.3787e-02, -1.7419e-02, -9.5184e-02,
          5.7518e-03, -6.7112e-03, -4.7046e-02,  1.2088e-02,  3.6290e-03,
          3.3149e-02, -5.6892e-02,  9.4841e-02,  5.0715e-02, -2.2248e-02,
         -8.2621e-02,  5.3056e-02, -1.2930e-01, -6.8697e-02,  4.3729e-04,
          2.8424e-02,  5.0135e-02,  9.6567e-02, -2.5901e-02,  4.1621e-02,
          6.7549e-02,  8.4700e-02, -6.3770e-02, -8.8865e-02,  1.0055e-01,
          4.4857e-02, -2.5308e-02,  3.0406e-02,  6.6954e-02, -2.5196e-02,
          9.7716e-02, -6.8991e-02,  3.1920e-02, -3.0777e-02, -6.2134e-02,
         -4.0739e-02,  7.1556e-02, -1.4735e-01, -4.3722e-02, -9.8682e-03,
          4.3134e-02,  1.2795e-01, -6.6669e-02,  3.1093e-02,  2.1885e-02,
         -8.5690e-02, -7.2746e-03,  4.8600e-02,  8.1860e-02, -6.4469e-02,
          3.6176e-02,  1.1555e-01, -4.6122e-02,  3.9147e-03, -4.5944e-02,
          4.7092e-04, -7.4116e-03, -6.2863e-02, -2.3449e-02, -1.2151e-01,
         -1.1478e-01,  8.2409e-02,  8.0685e-02, -1.0753e-01, -7.3171e-02,
          4.9677e-02, -2.7546e-02,  8.0186e-02],
        [-5.1654e-02, -4.7153e-02,  2.6584e-01,  3.2510e-02, -3.6413e-02,
         -5.7365e-03, -1.3240e-03, -1.3872e-01,  1.0799e-01,  1.9858e-01,
         -1.1783e-01,  3.4449e-01, -2.2945e-01,  9.3897e-02, -3.0180e-02,
          1.0405e-01, -1.0014e-01,  5.2071e-02,  5.2546e-02,  1.0682e-02,
          2.3945e-02, -6.0741e-02,  2.7344e-02,  3.4207e-01,  1.8094e-02,
         -1.4147e-01,  8.8688e-02, -8.8728e-02,  6.6176e-02,  8.0215e-02,
          1.4102e-01,  9.4215e-02, -2.1436e-02, -8.9684e-02,  2.5848e-01,
          1.2448e-01, -3.1948e-02, -3.7455e-02,  2.4212e-01, -2.7999e-02,
          1.4453e-01, -3.3786e-02,  3.4882e-03,  1.3954e-01, -8.7471e-03,
         -8.5231e-02, -5.2894e-02, -8.7290e-02, -1.6966e-02, -1.7081e-02,
          1.5769e-01,  6.1846e-02, -8.6180e-02, -1.1226e-01, -2.7229e-01,
         -2.3261e-02,  1.9142e-01, -1.6051e-01,  9.9079e-02, -5.7030e-02,
         -8.7964e-02,  5.7342e-02, -9.9314e-02,  3.9692e-02, -6.8644e-02,
          8.6204e-02,  1.5433e-01, -1.4119e-01, -8.3309e-02,  1.3936e-01,
          3.0595e-02, -2.2788e-03,  9.2033e-02,  8.0351e-02, -2.2799e-01,
          1.3568e-02,  1.4263e-02, -3.9452e-02,  3.0712e-02,  6.3089e-02,
         -3.8500e-02, -1.5615e-02,  1.4002e-02,  1.5464e-01,  6.9650e-03,
         -5.5617e-02, -5.5416e-02,  1.0041e-01, -3.7420e-02,  2.1713e-01,
         -2.3199e-01,  5.3223e-02,  9.7037e-02, -7.6342e-02,  5.9833e-02,
          3.9021e-02,  1.2844e-01,  3.0021e-01, -6.0693e-02,  2.9018e-01,
          3.7960e-02, -1.8992e-01, -2.0406e-02, -4.7685e-03,  4.7146e-02,
         -2.4784e-02,  1.7885e-02,  1.8863e-01,  3.2827e-02,  8.2001e-02,
          8.4859e-02, -8.4095e-02,  4.0594e-03, -1.5058e-02,  4.5472e-02,
         -2.3855e-02,  8.6404e-03,  5.7714e-04, -3.0933e-02,  2.3702e-02,
          9.5124e-02,  6.5190e-02,  1.0063e-01,  7.5900e-02,  3.2502e-02,
          1.3378e-01,  2.0875e-01,  5.6500e-02],
        [ 5.1333e-02,  4.8660e-02,  1.7362e-02, -7.7015e-03, -9.4598e-02,
          7.1695e-02, -4.3704e-02,  7.7020e-02, -2.5822e-02, -1.0518e-01,
          8.7502e-02,  4.7774e-03, -4.9605e-02,  6.1844e-02, -2.2493e-02,
          4.7214e-02,  4.4958e-02,  3.7528e-02, -3.5016e-02,  3.9168e-02,
          7.3266e-02,  7.8455e-02,  5.4611e-02,  1.5028e-03, -4.9954e-02,
          2.4270e-03,  2.4624e-03, -3.6496e-02, -2.7593e-02,  4.5631e-02,
         -4.1343e-02,  6.4276e-02, -5.8821e-02, -9.0695e-02,  2.9454e-03,
         -3.3613e-02,  3.0490e-02, -3.8236e-02, -1.2649e-01, -5.8500e-02,
         -9.7744e-02,  5.8467e-02,  9.1104e-02,  6.0574e-02, -1.1005e-02,
          5.8452e-02, -6.1356e-02, -4.1952e-02, -1.9744e-02, -3.9505e-02,
         -3.3101e-02,  2.4474e-02, -9.0622e-02,  4.6437e-02,  7.3980e-02,
         -3.7035e-02, -7.8049e-02, -9.9661e-02,  1.5689e-02, -4.1643e-02,
         -5.6309e-02, -3.5634e-03,  6.7215e-02, -5.8009e-02,  4.0000e-02,
         -7.4664e-02, -8.2758e-02,  4.3591e-02,  7.3379e-03, -3.6524e-02,
          6.6471e-02, -7.6472e-02, -1.0454e-01,  1.9077e-02, -7.9869e-02,
         -1.0615e-01, -3.4402e-02, -1.0618e-02, -5.7530e-02, -2.6123e-02,
         -4.1836e-02, -3.0972e-02, -2.3028e-02,  7.3523e-02, -8.4044e-02,
         -6.8676e-03, -3.1485e-02,  5.7907e-02, -5.4590e-02,  3.0206e-03,
          2.3148e-02, -5.6261e-02, -9.9790e-03, -5.0574e-02, -1.4116e-02,
          5.9974e-02, -8.9892e-02, -3.1396e-02,  1.6670e-02,  2.1712e-02,
          4.7518e-02,  6.9375e-02, -6.5989e-02,  5.9010e-02,  5.6250e-02,
         -2.6666e-03, -7.6600e-02, -7.9115e-02, -7.5929e-02, -7.4440e-02,
          2.7569e-02,  5.2814e-02, -4.9853e-02, -3.5116e-02, -9.8188e-02,
         -2.0451e-02, -5.2688e-02, -5.4090e-02, -4.5470e-02,  4.6187e-02,
          9.9805e-03, -4.5192e-03,  6.3231e-02, -4.4270e-02, -5.4550e-02,
          5.0676e-02,  3.6597e-02, -2.8144e-02]])), ('action_layer.bias', tensor([-0.0852, -0.1011,  0.0107,  0.2520,  0.1222, -0.0185, -0.1403])), ('value_layer.weight', tensor([[ 0.0374,  0.1155,  1.1388,  0.1288,  0.0509,  0.2467,  0.5012,  0.1855,
          0.4445,  0.2696,  1.1815,  0.2915,  0.6207,  0.3126,  0.0659,  0.3856,
          0.2747,  0.0633,  0.7824,  0.8507,  0.1360,  0.3021,  0.2582,  0.5076,
          0.2218,  0.3233,  0.9772,  0.9500,  0.4447,  0.8430,  0.2452,  0.9621,
          0.1026,  0.3235,  1.2512,  1.3246,  0.2066,  0.0246,  0.6233,  0.9228,
          0.4903,  0.1577,  0.1032,  0.5783,  0.3695,  0.7930,  0.4935,  0.1548,
          0.7874,  0.7935,  0.3993,  0.1178,  0.0999,  1.1274,  0.0897, -0.0060,
          1.1152,  0.3267,  0.2117,  0.2766,  0.9437,  0.3717,  0.1125,  0.2577,
          0.6865,  0.1497,  0.3548,  0.2403, -0.0182,  1.2658, -0.0096,  0.1150,
          1.3683,  0.1741,  1.2476,  1.4881,  0.2605,  0.2040,  0.6009,  0.6398,
          0.4124,  0.3784,  0.1177,  0.1096,  0.4895,  0.1034,  0.4996,  0.3867,
          0.5062,  0.4607,  0.3212,  1.1884,  0.2268,  0.2783,  0.3966,  0.3759,
          0.4746,  0.9493,  0.1330,  1.1679,  0.1973,  0.7877,  0.0748,  0.8074,
          0.1612,  0.0409,  0.4238,  0.2647,  0.2069,  0.5601,  0.0221,  0.6277,
          0.2221,  0.5562,  0.2563,  0.4650,  0.5942,  0.0377,  0.1923,  0.6707,
          1.2036,  0.7408,  0.3295,  0.8307,  0.1512,  0.5254,  0.6555,  0.0231]])), ('value_layer.bias', tensor([2.1831]))]))

def agent():
    return netAgent(model, incorrect_moves=False)